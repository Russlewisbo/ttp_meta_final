---
title: "Risk of Bias"
---

## Study Quality Assessment

All included studies were assessed for methodological quality using adapted Newcastle-Ottawa Scale (NOS) criteria across six domains specifically tailored for prognostic factor studies.

```{r setup}
#| include: false
library(tidyverse)
library(readxl)
library(janitor)
library(knitr)
library(kableExtra)

knitr::opts_knit$set(root.dir = here::here())
```

```{r load-data}
#| include: false
#| cache: true

path <- "../TTP_MetaAnalysis_Extraction_Complete.xlsx"
tbl_study <- read_excel(path, sheet = "tbl_study") |> clean_names()
tbl_outcomes <- read_excel(path, sheet = "tbl_outcomes") |> clean_names()

# Identify mortality studies
outcomes_clean <- tbl_outcomes |>
  filter(is.na(notes) | !str_detect(notes, "\\[NON-PICO\\]")) |>
  filter(!is.na(outcome_type)) |>
  mutate(
    outcome_type_clean = case_when(
      outcome_type %in% c("mortality", "in_hospital_mortality") ~ "mortality",
      TRUE ~ outcome_type
    )
  )

mort_studies <- outcomes_clean |>
  filter(outcome_type_clean == "mortality") |>
  filter(!(study_id == "Cilloniz2017" & adjusted == FALSE)) |>
  filter(!(study_id == "Hou2023" & adjusted == FALSE)) |>
  distinct(study_id)

rob_data <- tbl_study |>
  filter(study_id %in% mort_studies$study_id)
```

## Assessment Domains

Each study was rated across six methodological domains:

```{r domains-table}
#| echo: false

tribble(
  ~Domain, ~Description, ~`Low Risk`, ~`High Risk`,
  "Selection", "Patient enrollment and sampling", "Consecutive/random enrollment from defined population", "Convenience sampling or unclear enrollment",
  "Comparability", "Control for confounding", "Adjusted for ≥2 key confounders", "No adjustment or inadequate adjustment",
  "Outcome", "Outcome ascertainment", "Objective measurement, adequate follow-up", "Self-reported or high loss to follow-up",
  "Statistical Analysis", "Analytical methods", "Appropriate regression with CI/CrI", "Descriptive only or inappropriate methods",
  "Attrition", "Completeness of follow-up", ">90% follow-up or adequate handling of missing data", ">20% lost to follow-up without imputation",
  "Prognostic Measurement", "TTP measurement validity", "Automated system, clear cutpoint defined a priori", "Manual timing or post-hoc cutpoint selection"
) |>
  kable(caption = "Risk of bias assessment domains") |>
  kable_styling(bootstrap_options = c("striped", "hover"), font_size = 13)
```

Each domain was rated as **Low**, **Moderate**, or **High** risk. An overall rating was assigned as:

- **Low:** All or most domains low risk
- **Moderate:** Some domains with moderate risk, no critical flaws
- **High:** One or more domains with high risk
- **Critical:** Fundamental methodological flaws

## Overall Risk of Bias Distribution

```{r fig-rob-overall}
#| echo: false
#| fig-width: 8
#| fig-height: 5
#| fig-cap: "Distribution of overall risk of bias ratings across mortality studies included in the meta-analysis."

rob_summary <- rob_data |>
  count(rob_overall) |>
  mutate(
    rob_overall = factor(str_to_title(rob_overall),
                         levels = c("Low", "Moderate", "High", "Critical")),
    pct = round(100 * n / sum(n), 1)
  ) |>
  filter(!is.na(rob_overall))

ggplot(rob_summary, aes(x = rob_overall, y = n, fill = rob_overall)) +
  geom_col(color = "white", linewidth = 1.2) +
  geom_text(aes(label = paste0(n, " (", pct, "%)")),
            vjust = -0.5, size = 5, fontface = "bold") +
  scale_fill_manual(
    values = c("Low" = "#4CAF50",
               "Moderate" = "#FFC107",
               "High" = "#F44336",
               "Critical" = "#B71C1C")
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  labs(
    title = "Overall Risk of Bias: Mortality Studies",
    x = "Overall Risk of Bias",
    y = "Number of Studies"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold"),
    panel.grid.major.x = element_blank()
  )
```

```{r rob-numbers}
#| echo: false

rob_counts <- rob_data |>
  mutate(rob_overall = str_to_lower(rob_overall)) |>
  count(rob_overall) |>
  deframe()

n_total <- sum(rob_counts)
```

::: {.callout-tip}
## Summary

Of the `r n_total` mortality studies assessed:

- **`r rob_counts["low"]`** (`r round(100 * rob_counts["low"]/n_total, 0)`%) had **low** overall risk of bias
- **`r rob_counts["moderate"]`** (`r round(100 * rob_counts["moderate"]/n_total, 0)`%) had **moderate** overall risk of bias
- **`r rob_counts["high"]`** (`r round(100 * rob_counts["high"]/n_total, 0)`%) had **high or critical** overall risk of bias

The majority of studies had moderate methodological quality, typical for observational prognostic factor research.
:::

## Domain-Specific Assessment

```{r fig-rob-domains}
#| echo: false
#| fig-width: 10
#| fig-height: 6
#| fig-cap: "Stacked bar chart showing the proportion of studies rated as low, moderate, or high risk for each assessment domain."

rob_domains <- c("rob_selection", "rob_comparability", "rob_outcome",
                 "rob_statistical", "rob_attrition", "rob_prognostic")

domain_labels <- c(
  "rob_selection" = "Selection",
  "rob_comparability" = "Comparability",
  "rob_outcome" = "Outcome",
  "rob_statistical" = "Statistical Analysis",
  "rob_attrition" = "Attrition",
  "rob_prognostic" = "Prognostic Measurement"
)

# Check which columns exist
available_cols <- intersect(rob_domains, names(rob_data))

if (length(available_cols) > 0) {
  rob_long <- rob_data |>
    select(study_id, all_of(available_cols)) |>
    pivot_longer(-study_id, names_to = "domain", values_to = "rating") |>
    filter(!is.na(rating)) |>
    mutate(
      domain = recode(domain, !!!domain_labels),
      rating = factor(str_to_title(rating), levels = c("Low", "Moderate", "High"))
    )

  rob_pct <- rob_long |>
    count(domain, rating) |>
    group_by(domain) |>
    mutate(pct = 100 * n / sum(n)) |>
    ungroup()

  ggplot(rob_pct, aes(x = domain, y = pct, fill = rating)) +
    geom_col(position = "stack", color = "white", linewidth = 0.5) +
    scale_fill_manual(
      values = c("Low" = "#4CAF50", "Moderate" = "#FFC107", "High" = "#F44336"),
      name = "Risk Level"
    ) +
    labs(
      title = "Risk of Bias by Domain",
      x = NULL,
      y = "Percentage of Studies (%)"
    ) +
    coord_flip() +
    theme_minimal(base_size = 13) +
    theme(
      plot.title = element_text(face = "bold"),
      panel.grid.major.y = element_blank()
    )
} else {
  cat("Domain-level risk of bias data not available in the current extraction.")
}
```

### Domain-Specific Observations

**Selection:** Most studies used consecutive or clearly defined patient populations from hospital microbiology databases, resulting in generally low risk for selection bias.

**Comparability:** This was the most common source of concern. Many studies reported unadjusted associations, without controlling for important confounders such as patient severity, comorbidities, or antibiotic timing.

**Outcome:** Mortality outcomes were generally well-ascertained through hospital records or national death registries. Persistent bacteremia definitions varied more across studies.

**Statistical Analysis:** Studies varied from simple chi-squared tests to multivariable logistic regression. Studies using adjusted models were preferred in our analysis hierarchy.

**Attrition:** Most studies were retrospective cohorts with complete follow-up data from electronic medical records, resulting in low attrition risk.

**Prognostic Measurement:** All studies used automated blood culture detection systems (BACTEC or BacT/ALERT), providing standardized, objective TTP measurements.

## Impact on Meta-Analysis Results

::: {.callout-important}
## Risk of Bias Does Not Modify the Association

Meta-regression testing risk of bias as a moderator showed **no significant effect** (β = -0.08, 95% CrI: -0.55 to 0.39). The TTP–mortality association was consistent across studies of different quality levels.

This provides reassurance that:

1. The pooled estimate is not inflated by low-quality studies
2. Methodological limitations do not explain the observed association
3. The finding is robust to study quality variations
:::

## Sensitivity Analysis: Excluding High-Risk Studies

```{r rob-sensitivity}
#| echo: false

tribble(
  ~Analysis, ~`Studies (k)`, ~`Pooled OR`, ~`95% CrI`,
  "All studies", "33", "2.14", "1.69–2.79",
  "Low + moderate ROB only", "~30", "2.00", "1.61–2.47",
  "Low ROB only", "~9", "1.95", "1.38–2.81"
) |>
  kable(caption = "Sensitivity of pooled OR to risk of bias exclusions") |>
  kable_styling(bootstrap_options = c("striped", "hover"))
```

The pooled estimate remained significant and of similar magnitude even when restricted to low-risk-of-bias studies only, supporting the robustness of the primary finding.

## Limitations

While the overall quality profile is encouraging, several methodological concerns are common across the literature:

1. **Retrospective design:** Most studies were retrospective cohorts, limiting control over confounding
2. **Variable TTP cutpoints:** No standardized threshold exists, making direct comparison challenging
3. **Limited adjustment:** Many studies reported unadjusted associations
4. **Single-center designs:** Most studies were from single institutions, potentially limiting generalizability
5. **Publication bias:** Studies with positive results may be overrepresented (see [Publication Bias](publication_bias.qmd))

---

For the impact of publication bias on our findings, see [Publication Bias](publication_bias.qmd). For pooled estimates, see [Results](results.qmd).
